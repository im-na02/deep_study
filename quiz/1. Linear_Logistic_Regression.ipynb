{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab02 simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래의 독립변수와 종속변수 데이터로 linear hypothesis를 만드시오\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.1>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.5>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([ 4.6     ,  6.7     ,  8.799999, 10.9     , 13.      ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# data\n",
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "# weight 2.1\n",
    "##############################\n",
    "W = tf.Variable(2.1)\n",
    "##############################\n",
    "print(W)\n",
    "\n",
    "\n",
    "# bias 2.5\n",
    "##############################\n",
    "b = tf.Variable(2.5)\n",
    "##############################\n",
    "print(b)\n",
    "\n",
    "# hypothesis\n",
    "##############################\n",
    "hypothesis = x_data * W + b\n",
    "##############################\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 위의 hypothesis를 활용해서 linear regression의 cost 함수를 만드시오\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=36.059998>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# cost\n",
    "##############################\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "##############################\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient descent 1 epoch를 실행하시오\n",
    "현재 기울기, gradient descent 1 epoch 실행후 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.199997 11.599999\n",
      "원래 W와 b: 2.1 2.5\n",
      "원래 gradient 업데이트 후 W와 b: 1.708 2.384\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(7)\n",
    "\n",
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "W = tf.Variable(2.1)\n",
    "b = tf.Variable(2.5)\n",
    "\n",
    "# learning rate 0.01\n",
    "learning_rate = 0.01\n",
    "\n",
    "# gradient descent 1 epoch\n",
    "## GradientTape\n",
    "##############################\n",
    "with tf.GradientTape() as tape :\n",
    "    hypothesis = W * x_data + b\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "##############################\n",
    "\n",
    "## print current gradient\n",
    "##############################\n",
    "w_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "print(w_grad.numpy(), b_grad.numpy())\n",
    "##############################\n",
    "\n",
    "print('원래 W와 b:', W.numpy(), b.numpy())\n",
    "## update gradient\n",
    "##############################\n",
    "W.assign_sub(learning_rate * w_grad)\n",
    "b.assign_sub(learning_rate * b_grad)\n",
    "##############################\n",
    "\n",
    "\n",
    "## print updated gradient\n",
    "##############################\n",
    "print('원래 gradient 업데이트 후 W와 b:', W.numpy(), b.numpy())\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.GradientTape()로 y = x ^ 2에서 x = 3일 때의 기울기를 구하시오\n",
    "기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상수 x\n",
    "x = tf.constant(3.0)\n",
    "\n",
    "# GradientTape()\n",
    "#######################################\n",
    "with tf.GradientTape() as tape :\n",
    "    tape.watch(x)\n",
    "    y = x*x\n",
    "#######################################\n",
    "\n",
    "# x = 3일 때 gradient 출력\n",
    "#######################################\n",
    "tape.gradient(y, x).numpy() # 상수를 못 받고, variable만 받을 수 있음\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradient descent alorithm으로 파라미터를 101번 업데이트 하시오\n",
    "100번째 업데이트 후의 W, b 값과 cost 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 |\t1.7079999446868896 |\t2.384000062942505 |\t36.05999755859375\n",
      "10 |\t0.5413192510604858 |\t1.9879915714263916 |\t0.8665646314620972\n",
      "20 |\t0.47976887226104736 |\t1.9005126953125 |\t0.6615192294120789\n",
      "30 |\t0.4919293224811554 |\t1.8357959985733032 |\t0.6175261735916138\n",
      "40 |\t0.5085010528564453 |\t1.7745680809020996 |\t0.5770807862281799\n",
      "50 |\t0.5248445868492126 |\t1.7154686450958252 |\t0.5392872095108032\n",
      "60 |\t0.5406656265258789 |\t1.6583433151245117 |\t0.5039688348770142\n",
      "70 |\t0.5559612512588501 |\t1.6031209230422974 |\t0.47096362709999084\n",
      "80 |\t0.5707476139068604 |\t1.5497373342514038 |\t0.4401198923587799\n",
      "90 |\t0.5850416421890259 |\t1.498131275177002 |\t0.4112960696220398\n",
      "100 |\t0.5988597273826599 |\t1.448243498802185 |\t0.38435977697372437\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(2.1)\n",
    "b = tf.Variable(2.5)\n",
    "\n",
    "# learning rate 0.01\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 반복\n",
    "for i in range(100+1):\n",
    "    # GradientTape\n",
    "    #######################################\n",
    "    with tf.GradientTape() as tape :\n",
    "        hypothesis = W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    #######################################\n",
    "    \n",
    "    # 현재 기울기\n",
    "    #######################################\n",
    "    w_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "    #######################################\n",
    "    \n",
    "    # 업데이트 후 기울기\n",
    "    #######################################\n",
    "    W.assign_sub(learning_rate * w_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    #######################################\n",
    "    \n",
    "    # 10번 업데이트 후 W, b, cost 출력\n",
    "    #######################################\n",
    "    if i % 10 == 0 :\n",
    "        print(f'{i} |\\t{W.numpy()} |\\t{b.numpy()} |\\t{cost.numpy()}')\n",
    "    #######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab03 how to minimize cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression model의 cost function을 tensorflow 사용하지 않고 짜기(numpy 가능)\n",
    "hypothesis는 H(X) = W * X라고 가정하고, 아래 제시한 weight에 대해서 cost function의 값을 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.66666666666667\n",
      "54.85714285714287\n",
      "38.095238095238095\n",
      "24.380952380952383\n",
      "13.714285714285717\n",
      "6.095238095238099\n",
      "1.5238095238095248\n",
      "0.0\n",
      "1.5238095238095226\n",
      "6.0952380952380905\n",
      "13.714285714285703\n",
      "24.380952380952383\n",
      "38.09523809523808\n",
      "54.85714285714284\n",
      "74.66666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "# cost funtion 정의\n",
    "def cost_func(W, X, Y) :\n",
    "    #######################################\n",
    "    return np.square(W*X - Y).mean()\n",
    "    #######################################\n",
    "\n",
    "# 아래 제시한 w값에 대해 cost function 값 출력\n",
    "for feed_W in np.linspace(-3, 5, num = 15) :\n",
    "    #######################################\n",
    "    print(cost_func(feed_W, X, Y))\n",
    "    #######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression model의 cost function을 tensorflow로 짜기\n",
    "hypothesis는 H(X) = W * X라고 가정하고, 아래 제시한 weight에 대해서 cost function의 값을 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W : -3.00 | cost : 74.67\n",
      "W : -2.43 | cost : 54.86\n",
      "W : -1.86 | cost : 38.10\n",
      "W : -1.29 | cost : 24.38\n",
      "W : -0.71 | cost : 13.71\n",
      "W : -0.14 | cost :  6.10\n",
      "W :  0.43 | cost :  1.52\n",
      "W :  1.00 | cost :  0.00\n",
      "W :  1.57 | cost :  1.52\n",
      "W :  2.14 | cost :  6.10\n",
      "W :  2.71 | cost : 13.71\n",
      "W :  3.29 | cost : 24.38\n",
      "W :  3.86 | cost : 38.10\n",
      "W :  4.43 | cost : 54.86\n",
      "W :  5.00 | cost : 74.67\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "# cost function 정의(tensorflow 사용)\n",
    "def cost_func(W, X, Y) :\n",
    "    #######################################\n",
    "    return tf.reduce_mean(tf.square(X*W - Y))\n",
    "    #######################################\n",
    "    \n",
    "W_values = np.linspace(-3, 5, num=15)\n",
    "\n",
    "for feed_W in W_values :\n",
    "    print(f'W : {feed_W:5.2f} | cost : {cost_func(feed_W, X, Y):5.2f}')"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression model의 cost function이 아래와 같을 때 GradientTape 없이(그외 tensorflow code 사용가능) gradient descent를 구현하시오\n",
    "![image.png](attachment:image.png)\n",
    "매 10회마다 w, cost 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i :     0 | W : 45.59 | cost : 11716.31\n",
      "i :    10 | W : 14.91 | cost : 1139.18\n",
      "i :    20 | W :  5.34 | cost : 110.76\n",
      "i :    30 | W :  2.35 | cost : 10.77\n",
      "i :    40 | W :  1.42 | cost :  1.05\n",
      "i :    50 | W :  1.13 | cost :  0.10\n",
      "i :    60 | W :  1.04 | cost :  0.01\n",
      "i :    70 | W :  1.01 | cost :  0.00\n",
      "i :    80 | W :  1.00 | cost :  0.00\n",
      "i :    90 | W :  1.00 | cost :  0.00\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "W = tf.Variable(tf.random.normal([1], -100., 100.))\n",
    "\n",
    "w = []; c = []\n",
    "# 300회 gradient descent(update)\n",
    "for i in range(100) :\n",
    "    \n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    # 현재 gradient\n",
    "    #######################################\n",
    "    learning_rate = 0.01\n",
    "    gradient = tf.reduce_mean(tf.reduce_mean(tf.multiply(tf.multiply(W, x_data)-y_data, x_data)))\n",
    "    #######################################\n",
    "    \n",
    "    # gradient update\n",
    "    #######################################\n",
    "    descent = W - tf.multiply(learning_rate, gradient)\n",
    "    W.assign(descent)\n",
    "    #######################################\n",
    "    w.append(W.numpy()[0]); c.append(cost.numpy())\n",
    "    # 매 10회마다 출력\n",
    "    if i % 10 == 0 :\n",
    "        print(f'i : {i:5} | W : {W.numpy()[0]:5.2f} | cost : {cost:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab04 multi-variable linear regression(matrix!!!!!!!!!!!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래와 같이 데이터가 주어졌을 때 tensorflow의 matrix 연산으로 hypothesis와 cost function을 계산하는 식을 완전하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0 | cost : 1798.2894287109375\n",
      "i : 200 | cost : 1.985764741897583\n",
      "i : 400 | cost : 1.9071285724639893\n",
      "i : 600 | cost : 1.8354984521865845\n",
      "i : 800 | cost : 1.770180106163025\n",
      "i : 1000 | cost : 1.7105076313018799\n",
      "i : 1200 | cost : 1.655937910079956\n",
      "i : 1400 | cost : 1.6059433221817017\n",
      "i : 1600 | cost : 1.560052514076233\n",
      "i : 1800 | cost : 1.5178825855255127\n",
      "i : 2000 | cost : 1.4790351390838623\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "data = np.array([\n",
    "    [73, 80, 75, 152],\n",
    "    [93, 88, 93, 185],\n",
    "    [89, 91, 90, 180],\n",
    "    [96, 98, 100, 196],\n",
    "    [73, 66, 70, 142]],\n",
    "    dtype = np.float32)\n",
    "\n",
    "X = data[:, :-1]\n",
    "Y = data[:, [-1]]\n",
    "\n",
    "# W, b 에 tensorflow 변수 객체 할당\n",
    "#######################################\n",
    "W = tf.Variable(tf.random.normal([3,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "#######################################\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1) :\n",
    "    with tf.GradientTape() as tape :\n",
    "        # hypothesis, cost\n",
    "        ##################################### 채우시오\n",
    "        hypothesis = tf.matmul(X, W) + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "        #####################################\n",
    "        \n",
    "    W_grad, b_grad = tape.gradient(cost, [W,b])\n",
    "    \n",
    "    learning_rate = 0.00001\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 200 == 0 :\n",
    "        print(f'i : {i} | cost : {cost.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lab 05 logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logictic regression 구현에서 빈칸을 채우세요..^^;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.6874\n",
      "Iter: 100, Loss: 0.5776\n",
      "Iter: 200, Loss: 0.5349\n",
      "Iter: 300, Loss: 0.5054\n",
      "Iter: 400, Loss: 0.4838\n",
      "Iter: 500, Loss: 0.4671\n",
      "Iter: 600, Loss: 0.4535\n",
      "Iter: 700, Loss: 0.4420\n",
      "Iter: 800, Loss: 0.4319\n",
      "Iter: 900, Loss: 0.4228\n",
      "Iter: 1000, Loss: 0.4144\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# seed 설정\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 훈련/테스트 데이터\n",
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "# batch size(한번에 학습시킬 양) 설정\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "# tensorflow Variable 설정\n",
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "\n",
    "# 가설 설정 함수\n",
    "def logistic_regression(features):\n",
    "    ##############################################\n",
    "    hypothesis  = tf.divide(1., 1 + tf.exp(tf.matmul(features, W) + b))\n",
    "    ##############################################\n",
    "    return hypothesis\n",
    "\n",
    "# cost/loss function 함수\n",
    "def loss_fn(features, labels):\n",
    "    ##############################################\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + \\\n",
    "                           (1 - labels) * tf.math.log(1 - logistic_regression(features)))\n",
    "    ##############################################\n",
    "    return cost\n",
    "\n",
    "# cost function에서 gradient 구하는 함수\n",
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(features,labels)\n",
    "    ##############################################\n",
    "    return tape.gradient(loss_value, [W,b])\n",
    "    ##############################################\n",
    "\n",
    "# optimizer : SGD\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01) ###################\n",
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b])) ##########################\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(features,labels)))\n",
    "            \n",
    "# accuracy 구하는 함수\n",
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)  ############\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy            \n",
    "\n",
    "# 학습 완료 후 accuracy를 구하시오\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b8a0e835c8>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
